<!DOCTYPE HTML><html><head><title>RSS Team 13</title><link rel="stylesheet" type="text/css" href="../../css/style.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']],displayMath: [['$$','$$']],skipTags: ["script","noscript","style","textarea","code"]},TeX: {equationNumbers: {autoNumber: "AMS"}}});</script><script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"></script></head><body><div id="main"><div id="logo"><div id="logo_text"><h1><a href="../.."><span class="logo_colour">RSS Team 13</span></a></h1><h2>MIT Spring 2019</h2></div></div><div id="header"><div id="menubar"><ul id="menu"><li class=""><a href="../..">Home</a></li><li class="selected"><a href="../../labs">Labs</a></li><li><a href="https://www.youtube.com/watch?v=dQw4w9WgXcQ">Video</a></li><li><a href="https://github.mit.edu/rss2019-13">Github</a></li></ul></div></div><div id="site_content"><div id="content"><h1>Lab 3</h1>
For Lab 3, our goal was to give our robot wall-following abilities as well as a safety controller that prevented collisions. In order to do this, we created a hierarchy of programs that would allow the robot to efficiently follow walls without causing harm to itself or its surroundings.
<h2>Table of Contents</h2>
<ol>
<li>Scan Parser</li>
</ol>
<ol>
<li>Wall Follower</li>
</ol>
<ol>
<li>Safety Controller</li>
</ol>
<h2>Scan Parser</h2>
Our racecar uses a LIDAR 2D laser scanner to collect data about its surroundings. This is given to the car in a series of polar coordinates, which represent the distance to the nearest obstacle at any given angle in the sweep. We looked at specific subsets of this data that varied based on the task we were looking to accomplish. Once this data was filtered, we converted the laserscan data from polar coordinates to cartesian coordinates to make it easier to work with.
<h2>Wall Follower</h2>
Our wall follower worked in three parts. First, we used the laserscan data to determine where the walls were relative to the robot. From here we determined the error of the car's position relative to its desired position. Finally, we implemented a controller that changed the turning angle of the car in order to direct it back to its desired position.
<h3>Wall Detector</h3>
Once we had received the LaserScan data from the LIDAR, we filtered out points that were not relevant. In the wall-following situation, this meant that we only looked at points to the left and in front of the racecar if it was following the left wall, and only looked at points to the right and in front of the racecar if it was following the left wall. From here, we were able to use a simple linear regression to consider all the LaserScan points on the correct side of the robot, and create a linear model for the wall that represented its location relative to the robot.
<h3>Error Measurement</h3>
Once we knew where the wall was located, we needed to know two things: the distance the robot was positioned from the wall, and the angle it was rotated relative to the wall. We used trigonometry and algebra to find these values. From here we calculated the error values by simple subtracting the measured distances and angles from the desired distance and angle, in which the angle we want is as parallel to the wall as possible.
<h3>Wall Follower Controller</h3>
Using our error values, we implemented a PD controller that allows the racecar to adjust its turning angle based on its previous error from the desired position. We multiplied each error by some gain constant and published the sum to the Ackermann Drive message of the robot as the turning angle. The racecar then adjusted its wheels to follow this turning angle, and from here out feedback cycle would start again, measuring the new errors from the LIDAR data and computing a new turning angle.
<h2>Safety Controller</h2>
<h3>Object Detection</h3>
<h3>Detecting Unsafe Situations</h3>
<h3>Collision Prevention Controller</h3>
</div></div></div></body></html>